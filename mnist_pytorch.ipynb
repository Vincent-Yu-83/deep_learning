{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (mlp): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "[epoch=1, batch_index=300, training_loss=1.2714736098051072]\n",
      "[epoch=1, batch_index=600, training_loss=0.793694501320521]\n",
      "Accuracy on test set:75.8\n",
      "[epoch=2, batch_index=300, training_loss=0.7064015754063924]\n",
      "[epoch=2, batch_index=600, training_loss=0.7031087816754977]\n",
      "Accuracy on test set:77.03\n",
      "[epoch=3, batch_index=300, training_loss=0.6625345994035403]\n",
      "[epoch=3, batch_index=600, training_loss=0.6623666089773178]\n",
      "Accuracy on test set:77.15\n",
      "[epoch=4, batch_index=300, training_loss=0.6447220640381177]\n",
      "[epoch=4, batch_index=600, training_loss=0.5871825753152371]\n",
      "Accuracy on test set:84.59\n",
      "[epoch=5, batch_index=300, training_loss=0.4390145862599214]\n",
      "[epoch=5, batch_index=600, training_loss=0.4344100801646709]\n",
      "Accuracy on test set:85.33\n",
      "[epoch=6, batch_index=300, training_loss=0.4139862689375877]\n",
      "[epoch=6, batch_index=600, training_loss=0.29269479685773453]\n",
      "Accuracy on test set:94.47\n",
      "[epoch=7, batch_index=300, training_loss=0.1874701401591301]\n",
      "[epoch=7, batch_index=600, training_loss=0.1769963524552683]\n",
      "Accuracy on test set:94.7\n",
      "[epoch=8, batch_index=300, training_loss=0.16343977734446524]\n",
      "[epoch=8, batch_index=600, training_loss=0.16803749963020284]\n",
      "Accuracy on test set:95.15\n",
      "[epoch=9, batch_index=300, training_loss=0.14868784279872974]\n",
      "[epoch=9, batch_index=600, training_loss=0.14879738116015992]\n",
      "Accuracy on test set:95.55\n",
      "[epoch=10, batch_index=300, training_loss=0.1356804842626055]\n",
      "[epoch=10, batch_index=600, training_loss=0.14299133097132047]\n",
      "Accuracy on test set:95.46\n",
      "[epoch=11, batch_index=300, training_loss=0.13315168959399065]\n",
      "[epoch=11, batch_index=600, training_loss=0.12503834010412296]\n",
      "Accuracy on test set:95.69\n",
      "[epoch=12, batch_index=300, training_loss=0.12710060257464648]\n",
      "[epoch=12, batch_index=600, training_loss=0.1190136851494511]\n",
      "Accuracy on test set:95.79\n",
      "[epoch=13, batch_index=300, training_loss=0.12178809114421407]\n",
      "[epoch=13, batch_index=600, training_loss=0.11006638512636224]\n",
      "Accuracy on test set:95.94\n",
      "[epoch=14, batch_index=300, training_loss=0.11019820696674287]\n",
      "[epoch=14, batch_index=600, training_loss=0.10980659741908312]\n",
      "Accuracy on test set:96.06\n",
      "[epoch=15, batch_index=300, training_loss=0.10147969032948216]\n",
      "[epoch=15, batch_index=600, training_loss=0.11065500729406873]\n",
      "Accuracy on test set:96.3\n",
      "[epoch=16, batch_index=300, training_loss=0.10088305593157808]\n",
      "[epoch=16, batch_index=600, training_loss=0.10164654686115682]\n",
      "Accuracy on test set:96.4\n",
      "[epoch=17, batch_index=300, training_loss=0.09546502382184069]\n",
      "[epoch=17, batch_index=600, training_loss=0.09978583077589671]\n",
      "Accuracy on test set:96.28\n",
      "[epoch=18, batch_index=300, training_loss=0.09567879899715384]\n",
      "[epoch=18, batch_index=600, training_loss=0.09675007392962774]\n",
      "Accuracy on test set:96.36\n",
      "[epoch=19, batch_index=300, training_loss=0.09191424252775808]\n",
      "[epoch=19, batch_index=600, training_loss=0.09131355879828335]\n",
      "Accuracy on test set:96.4\n",
      "[epoch=20, batch_index=300, training_loss=0.08725665721110999]\n",
      "[epoch=20, batch_index=600, training_loss=0.08720542700961233]\n",
      "Accuracy on test set:96.43\n",
      "[epoch=21, batch_index=300, training_loss=0.08265672145411372]\n",
      "[epoch=21, batch_index=600, training_loss=0.0898048317246139]\n",
      "Accuracy on test set:96.61\n",
      "[epoch=22, batch_index=300, training_loss=0.08086504625156522]\n",
      "[epoch=22, batch_index=600, training_loss=0.08054708541526148]\n",
      "Accuracy on test set:96.55\n",
      "[epoch=23, batch_index=300, training_loss=0.08088835222336153]\n",
      "[epoch=23, batch_index=600, training_loss=0.0775737766145418]\n",
      "Accuracy on test set:96.58\n",
      "[epoch=24, batch_index=300, training_loss=0.08008215406909586]\n",
      "[epoch=24, batch_index=600, training_loss=0.07684931005040804]\n",
      "Accuracy on test set:96.64\n",
      "[epoch=25, batch_index=300, training_loss=0.07789373730619749]\n",
      "[epoch=25, batch_index=600, training_loss=0.07435936171871921]\n",
      "Accuracy on test set:96.64\n",
      "[epoch=26, batch_index=300, training_loss=0.07268378857212762]\n",
      "[epoch=26, batch_index=600, training_loss=0.07478958312732478]\n",
      "Accuracy on test set:96.64\n",
      "[epoch=27, batch_index=300, training_loss=0.07032779956236482]\n",
      "[epoch=27, batch_index=600, training_loss=0.07272728845166664]\n",
      "Accuracy on test set:96.69\n",
      "[epoch=28, batch_index=300, training_loss=0.07014549088353912]\n",
      "[epoch=28, batch_index=600, training_loss=0.06735068798375626]\n",
      "Accuracy on test set:96.59\n",
      "[epoch=29, batch_index=300, training_loss=0.06671076085418463]\n",
      "[epoch=29, batch_index=600, training_loss=0.06996280782235166]\n",
      "Accuracy on test set:96.73\n",
      "[epoch=30, batch_index=300, training_loss=0.06426740310465297]\n",
      "[epoch=30, batch_index=600, training_loss=0.06637835673211763]\n",
      "Accuracy on test set:96.62\n",
      "[epoch=31, batch_index=300, training_loss=0.06410895245304953]\n",
      "[epoch=31, batch_index=600, training_loss=0.06809066952206194]\n",
      "Accuracy on test set:96.69\n",
      "[epoch=32, batch_index=300, training_loss=0.06345306988495092]\n",
      "[epoch=32, batch_index=600, training_loss=0.06360810265876353]\n",
      "Accuracy on test set:96.67\n",
      "[epoch=33, batch_index=300, training_loss=0.060687213658044734]\n",
      "[epoch=33, batch_index=600, training_loss=0.0643330422245587]\n",
      "Accuracy on test set:96.66\n",
      "[epoch=34, batch_index=300, training_loss=0.06051430689791838]\n",
      "[epoch=34, batch_index=600, training_loss=0.06155429533682764]\n",
      "Accuracy on test set:96.67\n",
      "[epoch=35, batch_index=300, training_loss=0.06141742655696968]\n",
      "[epoch=35, batch_index=600, training_loss=0.06105960198057195]\n",
      "Accuracy on test set:96.62\n",
      "[epoch=36, batch_index=300, training_loss=0.05861136168707162]\n",
      "[epoch=36, batch_index=600, training_loss=0.0578018008886526]\n",
      "Accuracy on test set:96.82\n",
      "[epoch=37, batch_index=300, training_loss=0.057211114804570876]\n",
      "[epoch=37, batch_index=600, training_loss=0.059790590728322664]\n",
      "Accuracy on test set:96.75\n",
      "[epoch=38, batch_index=300, training_loss=0.05486373072179655]\n",
      "[epoch=38, batch_index=600, training_loss=0.05885243600234389]\n",
      "Accuracy on test set:96.64\n",
      "[epoch=39, batch_index=300, training_loss=0.056681612728474044]\n",
      "[epoch=39, batch_index=600, training_loss=0.05430590011024227]\n",
      "Accuracy on test set:96.68\n",
      "[epoch=40, batch_index=300, training_loss=0.0505233204504475]\n",
      "[epoch=40, batch_index=600, training_loss=0.05645895794965327]\n",
      "Accuracy on test set:96.67\n",
      "[epoch=41, batch_index=300, training_loss=0.052627263693138956]\n",
      "[epoch=41, batch_index=600, training_loss=0.053443884472362695]\n",
      "Accuracy on test set:96.66\n",
      "[epoch=42, batch_index=300, training_loss=0.05180570072028786]\n",
      "[epoch=42, batch_index=600, training_loss=0.05193419935336958]\n",
      "Accuracy on test set:96.59\n",
      "[epoch=43, batch_index=300, training_loss=0.05259328923653811]\n",
      "[epoch=43, batch_index=600, training_loss=0.05073127014407267]\n",
      "Accuracy on test set:96.56\n",
      "[epoch=44, batch_index=300, training_loss=0.0502354022130991]\n",
      "[epoch=44, batch_index=600, training_loss=0.0519045011450847]\n",
      "Accuracy on test set:96.72\n",
      "[epoch=45, batch_index=300, training_loss=0.04644106698222458]\n",
      "[epoch=45, batch_index=600, training_loss=0.05261240505613387]\n",
      "Accuracy on test set:96.61\n",
      "[epoch=46, batch_index=300, training_loss=0.04609566963277757]\n",
      "[epoch=46, batch_index=600, training_loss=0.051329917224744954]\n",
      "Accuracy on test set:96.82\n",
      "[epoch=47, batch_index=300, training_loss=0.04820961177969972]\n",
      "[epoch=47, batch_index=600, training_loss=0.04946683530385296]\n",
      "Accuracy on test set:96.67\n",
      "[epoch=48, batch_index=300, training_loss=0.04915369789892187]\n",
      "[epoch=48, batch_index=600, training_loss=0.04443334944546223]\n",
      "Accuracy on test set:96.77\n",
      "[epoch=49, batch_index=300, training_loss=0.04521438368751357]\n",
      "[epoch=49, batch_index=600, training_loss=0.046834827726706864]\n",
      "Accuracy on test set:96.77\n",
      "[epoch=50, batch_index=300, training_loss=0.04558094584538291]\n",
      "[epoch=50, batch_index=600, training_loss=0.04535752139830341]\n",
      "Accuracy on test set:96.73\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "# 加载mnist.pkl.gz\n",
    "def load_data_pickle(data_path, filename, batchSize):\n",
    "    # 解压缩数据集\n",
    "    with gzip.open((PATH/FILENAME).as_posix(),\"rb\") as f:\n",
    "        ((x_train,y_train),(x_valid,y_valid),(x_test,y_test))=pickle.load(f,encoding=\"iso-8859-1\")\n",
    "    #x_train(50000,784),y_train(50000,) x_valid(10000, 784),y_valid(10000,) x_test(10000, 784),y_test(10000,)\n",
    "    #=================数据转为tensor才能参与建模训练===\n",
    "    x_train,y_train,x_valid,y_valid,x_test,y_test=map(torch.tensor, (x_train,y_train,x_valid,y_valid,x_test,y_test))\n",
    "    train_loader = DataLoader(TensorDataset(x_train,y_train), \n",
    "                              shuffle=True, \n",
    "                              batch_size=batchSize, \n",
    "                              drop_last=True)\n",
    "    valid_loader = DataLoader(TensorDataset(x_valid,y_valid), \n",
    "                              shuffle=True, \n",
    "                              batch_size=batchSize, \n",
    "                              drop_last=True)\n",
    "    test_loader = DataLoader(TensorDataset(x_test,y_test), \n",
    "                             shuffle=True, \n",
    "                             batch_size=batchSize, \n",
    "                              drop_last=False)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "# 加载mnist datasets\n",
    "def load_data(data_path, batchSize):\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #均值=0.1307，标准差=0.3081\n",
    "        transforms.Normalize((0.1307,),(0.3081,))\n",
    "    ])\n",
    "    trainset=datasets.MNIST(root=data_path, \n",
    "                            train=True, \n",
    "                            download=True, \n",
    "                            transform=transform)\n",
    "    test_dataset=datasets.MNIST(root=data_path, \n",
    "                                train=False, \n",
    "                                download=True, \n",
    "                                transform=transform)\n",
    "    \n",
    "    # 将训练集分为训练和验证集\n",
    "    train_size = int(0.8 * len(trainset))\n",
    "    valid_size = len(trainset) - train_size\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(trainset, [train_size, valid_size])\n",
    "    \n",
    "    train_loader=DataLoader(train_dataset, \n",
    "                            shuffle=True, \n",
    "                            batch_size=batchSize, \n",
    "                            drop_last=True)\n",
    "    valid_loader=DataLoader(valid_dataset, \n",
    "                            shuffle=True, \n",
    "                            batch_size=batchSize, \n",
    "                            drop_last=True)\n",
    "    test_loader=DataLoader(test_dataset, \n",
    "                           shuffle=True, \n",
    "                           batch_size=batchSize, \n",
    "                            drop_last=False)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "# 验证数据集，随机显示数字\n",
    "def showRandomPictures(data_loader):\n",
    "    data_iter=iter(data_loader)\n",
    "    images,labels=data_iter.__next__()\n",
    "    # Choose a random index from the batch\n",
    "    random_index = random.randint(0, batchSize - 1)\n",
    " \n",
    "    # Display the transformed image\n",
    "    transformed_image = images[random_index].squeeze().numpy()\n",
    "    transformed_image = (transformed_image * 0.3081) + 0.1307  # Inverse normalization\n",
    "    plt.imshow(transformed_image, cmap='gray')  # Assuming MNIST images are grayscale\n",
    "    plt.title(f\"Label: {labels[random_index].item()}\")\n",
    "    plt.show() \n",
    "\n",
    "# 用序列容器创建模型架构\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes, function) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.mlp = nn.Sequential()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            # 序列容器可以对每层进行命名\n",
    "            self.mlp.add_module(\n",
    "                name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            self.mlp.add_module(name=\"A{:d}\".format(i), module=function)\n",
    "\n",
    "        # self.dropout=nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入的图像变为1行784列的向量，通俗的说就是将一张28 ✖ 28的图像的所有像素值拼起来，-1表示自动计算N的值（N表示样本数量）\n",
    "        x = x.view(-1,784)\n",
    "        x = self.mlp(x)\n",
    "        # x=self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# 使用模型数组创建模型架构\n",
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes, function):\n",
    "        super(Net2, self).__init__()\n",
    "        self.mlp = nn.ModuleList()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.mlp.append(nn.Linear(in_size, out_size))\n",
    "            self.mlp.append(function)\n",
    "        \n",
    "        # self.dropout=nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入的图像变为1行784列的向量，通俗的说就是将一张28 ✖ 28的图像的所有像素值拼起来，-1表示自动计算N的值（N表示样本数量）\n",
    "        x = x.view(-1,784)\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.mlp):\n",
    "            x = l(x)\n",
    "        \n",
    "        # x=self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(epoch, train_loader, model, loss_func, optimizer):\n",
    "    running_loss=0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        # 将模型设置为训练模式。当模型包含 Batch Normalization 和 Dropout 等层时，这个方法确保这些层在训练阶段能够正常工作。\n",
    "        model.train() #更新w和b\n",
    "        inputs,target=data\n",
    "        # 在每次调用正向传播之后需要optimizer.zero_grad()进行梯度清零操作，不然梯度就会不断累加。\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        outputs=model(inputs)\n",
    "        loss=loss_func(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #running_loss 是用来记录累计的loss值，累加loss直接用loss.item()，不然的话就是计算图，用item取出就是数值。\n",
    "        running_loss+=loss.item()\n",
    "        if batch_idx%300==299:\n",
    "            print(f\"[epoch={epoch+1}, batch_index={batch_idx+1}, training_loss={running_loss/300}]\")\n",
    "            running_loss=0.0\n",
    "\n",
    "\n",
    "def test(test_loader, model):\n",
    "    correct=0\n",
    "    total=0\n",
    "    model.eval() #不更新w和b\n",
    "    # 验证集合不需要进行反向传播，只需要进行正向，所以用 no_grad() 来取消梯度\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images,labels=data\n",
    "            outputs=model(images)\n",
    "            #每一行的最大值的下标[max,maxIndex] dim = 1 表示行，dim = 0表示列\n",
    "            _,predicted=torch.max(outputs.data,dim=1)\n",
    "            #label.size(0)是batch_size 表示取元组的第一个数，这里labels.size(0)返回的是N\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "    print(f\"Accuracy on test set:{100*correct/total}\")\n",
    "    return 100*correct/total\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    # 定义数据集文件目录\n",
    "    DATA_PATH=Path(\"/root/projects/yesu/deep_learning/Neural_Network/data_sets\")\n",
    "    PATH=DATA_PATH / \"\"\n",
    "    FILENAME=\"mnist.pkl.gz\"\n",
    "    \n",
    "    #=====torch.nn.functional==========\n",
    "    # 交叉熵函数\n",
    "    loss_func = F.cross_entropy\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # 定义感知机形状\n",
    "    layer_sizes = [784, 30, 10]\n",
    "    # layer_sizes = [784, 512, 256, 128, 64, 10]\n",
    "    \n",
    "    # 激活函数\n",
    "    function = torch.nn.ReLU()\n",
    "    # 初始化多层感知机\n",
    "    net=Net2(layer_sizes, function)\n",
    "    print(net)\n",
    "    \n",
    "    # 使用SGD算法构建梯度更新对象\n",
    "    # 更新net里所有参数\n",
    "    # 定义学习率\n",
    "    # 定义动量因子和权重衰减\n",
    "    optimizer=optim.SGD(net.parameters(), lr=0.01, momentum=0.5, weight_decay=5e-4)\n",
    "    \n",
    "    # 每16个epoch之后，lr变为原来的0.2\n",
    "    # scheduler1 = lr_scheduler.StepLR(optimizer,step_size=16,gamma=0.2)  \n",
    "    # scheduler1 = lr_scheduler.ExponentialLR(optimizer, gamma=0.95) # 每个epoch，lr变为原来的0.95\n",
    "    # scheduler1 = lr_scheduler.MultistepLR(optimizer,milestones=[10,20],gamma=0.5)# 10epoch后变为原来0.5，20 epoch后又衰减0.5\n",
    "    # 查看学习率\n",
    "    # scheduler1.get_lr()[0]\n",
    "    \n",
    "    # 前5个epoch，从0.001增加到0.04，之后按scheduler1变化lr\n",
    "    # scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=40, total_epoch=5, after_scheduler=scheduler1)\n",
    "    # 查看学习率\n",
    "    # scheduler_warmup.get_lr()[0]\n",
    "    \n",
    "    # 小批量数据集大小\n",
    "    batchSize=64\n",
    "    # 生成小批量数据集\n",
    "    train_loader, valid_loader, test_loader = load_data(PATH, batchSize)\n",
    "    # train_loader, valid_loader, test_loader = load_data_pickle(PATH, FILENAME, batchSize)\n",
    "    # showRandomPictures(train_loader)\n",
    "    #打印定义好的名字和w和b\n",
    "    # for name,parameter in net.named_parameters():\n",
    "    #     print(name,parameter,parameter.size())\n",
    "    \n",
    "    accuracyHistory=[]\n",
    "    for epoch in range(50):\n",
    "        train(epoch, train_loader, net, loss_func, optimizer)\n",
    "        ah = test(test_loader, net)\n",
    "        # 调整学习率\n",
    "        # scheduler1.step()\n",
    "        # scheduler_warmup.step()  \n",
    "        accuracyHistory.append(ah)\n",
    "    plt.plot(accuracyHistory)\n",
    "    plt.show()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
